{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58db20d4",
   "metadata": {},
   "source": [
    "# Notebook 3: Retrieval + Augmented + Generation (RAG)\n",
    "\n",
    "En este notebook unificamos las tres partes del sistema RAG que hemos visto:\n",
    "\n",
    "1. **Retrieval**: buscar información relevante de una base de datos vectorial\n",
    "2. **Augmented**: construir el *contexto* textual a partir de los documentos recuperados\n",
    "3. **Generation**: generar una respuesta usando un modelo de lenguaje (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba5e1a",
   "metadata": {},
   "source": [
    "## 1. Configurar conexión a Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d757b59a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    host=\"rag-weaviate\",\n",
    "    port=8080,\n",
    "    grpc_port=50051\n",
    ")\n",
    "collection = client.collections.get(\"Note\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe736e1a",
   "metadata": {},
   "source": [
    "## 2. Configurar conexión a Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7401690d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! 😊 Estoy muy bien, gracias por preguntar.  ¿Y tú, cómo estás? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "OLLAMA_URL = \"http://rag-ollama:11434\"\n",
    "MODEL = \"gemma2:2b\" \n",
    "\n",
    "def ask_ollama(prompt: str):\n",
    "    response = requests.post(\n",
    "        f\"{OLLAMA_URL}/api/generate\",\n",
    "        json={\n",
    "            \"model\": MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    print(response.json()[\"response\"])\n",
    "\n",
    "ask_ollama(\"Hola, ¿Cómo estas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda90fb",
   "metadata": {},
   "source": [
    "## 3. Cargar modelo de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a107a9d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1580a3",
   "metadata": {},
   "source": [
    "## 4. Definir consulta, vectorizar y recuperar documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f292f89d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000] Componentes de Hadoop - Infraestructuras de Big Data\n",
      "[0.479] Control de versiones con Git - Fundamentos de Ingeniería del Software\n",
      "[0.079] Ciclo de vida del software - Fundamentos de Ingeniería del Software\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Qué ventajas tiene usar procesamiento distribuido con Hadoop?\"\n",
    "\n",
    "vector = embedder.encode(query)\n",
    "\n",
    "results = collection.query.hybrid(\n",
    "    query=query,\n",
    "    vector=vector,\n",
    "    alpha=0.5,\n",
    "    limit=3,\n",
    "    include_vector=False,\n",
    "    return_metadata=[\"score\"]\n",
    ")\n",
    "\n",
    "for r in results.objects:\n",
    "    print(f\"[{r.metadata.score:.3f}] {r.properties['title']} - {r.properties['subject']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fe999",
   "metadata": {},
   "source": [
    "## 5. Construir contexto a partir de las notas recuperadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc893a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto generado para el modelo:\n",
      "\n",
      "[Componentes de Hadoop (Infraestructuras de Big Data, 2024.0)]: Hadoop está compuesto por HDFS para almacenamiento, YARN para gestión de recursos y MapReduce para procesamiento.\n",
      "[Control de versiones con Git (Fundamentos de Ingeniería del Software, 2023.0)]: Git permite gestionar versiones del código fuente de forma distribuida, facilitando el trabajo colaborativo entre desarrolladores.\n",
      "[Ciclo de vida del software (Fundamentos de Ingeniería del Software, 2023.0)]: El ciclo de vida del software incluye etapas como análisis de requisitos, diseño, implementación, pruebas y mantenimiento.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for r in results.objects:\n",
    "    title = r.properties[\"title\"]\n",
    "    subject = r.properties[\"subject\"]\n",
    "    year = r.properties[\"year\"]\n",
    "    text = r.properties[\"text\"]\n",
    "    chunks.append(f\"[{title} ({subject}, {year})]: {text}\")\n",
    "\n",
    "context = \"\\n\".join(chunks)\n",
    "\n",
    "print(\"Contexto generado para el modelo:\\n\")\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcdadf1",
   "metadata": {},
   "source": [
    "## 6. Construir prompt final y generar respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278e7ba8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El procesamiento distribuido con Hadoop ofrece varias ventajas clave: \n",
      "\n",
      "**1. Escalabilidad:**  Puedes agregar más nodos al cluster de Hadoop cuando necesites procesar más datos. Esto permite que el sistema se escalase para manejar grandes conjuntos de datos sin problemas.\n",
      "\n",
      "**2. Eficiencia en el almacenamiento y procesamiento:** HDFS (Hadoop Distributed File System) organiza los datos de forma eficiente, optimizando el acceso y la velocidad de procesamiento. \n",
      "\n",
      "**3.  Flexibilidad:**  MapReduce, un framework de código abierto para procesamiento distribuido, permite a los usuarios ejecutar tareas de análisis de datos en diferentes nodos del cluster, lo que les da gran flexibilidad.\n",
      "\n",
      "**4.  Reducción de tiempo de procesamiento:** Al dividir las tareas de procesamiento en múltiples nodos, Hadoop reduce el tiempo de ejecución del trabajo y facilita la optimización de recursos. \n",
      "\n",
      "**5.  Mejor control de errores:** La naturaleza distribuida de Hadoop permite detectar y solucionar errores de forma más rápida y eficaz.\n",
      "\n",
      "\n",
      "En resumen, usar procesamiento distribuido con Hadoop ofrece una gran cantidad de ventajas en cuanto a escalabilidad, eficiencia y flexibilidad, lo que lo convierte en una solución ideal para el análisis de datos masivo. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    f\"A continuación tienes apuntes de clase relevantes:\\n\\n\"\n",
    "    f\"{context}\\n\\n\"\n",
    "    f\"En base a estos apuntes, responde a esta pregunta:\\n{query}\"\n",
    ")\n",
    "\n",
    "ask_ollama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2576a-ca93-42bd-8736-d12d1bf1852e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
